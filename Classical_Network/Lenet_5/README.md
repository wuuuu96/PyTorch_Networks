### ç¯å¢ƒpython==3.10 pytorch==2.3.1 cuda==12.1
### modelè¿è¡Œç»“æœ: input:1x28x28    Total params:61,706
### modelè¿è¡Œç»“æœ: input:3x32x32    Total params:83,126
### è®ºæ–‡ä¸­modelè®­ç»ƒç»“æœ: Sigmoid + Avgpool2d + æ²¡æœ‰Dropout epoch=100 val_acc=87.34%
### æ”¹è¿›modelè®­ç»ƒç»“æœ_1: ReLU + MaxPool + Dropout + AdamW + OneCycleLR + label smoothing epoch=100 val_acc=89.68%
### 1.è§†é¢‘è®²è§£

- ğŸ“º:[LeNet-5ç½‘ç»œè¯ç”ŸèƒŒæ™¯](https://www.bilibili.com/video/BV1e34y1M7wR?spm_id_from=333.788.videopod.episodes&vd_source=ee0d4853ce8dacb7fdfc07d40e328f36&p=32)

- ğŸ“º:[LeNet-5ç½‘ç»œå‚æ•°è¯¦è§£](https://www.bilibili.com/video/BV1e34y1M7wR?spm_id_from=333.788.videopod.episodes&vd_source=ee0d4853ce8dacb7fdfc07d40e328f36&p=33)

<img width="1444" height="752" alt="image" src="https://github.com/user-attachments/assets/e57b9cc7-7bad-4102-b92f-f9f919f276ca" />

<img width="1296" height="633" alt="image" src="https://github.com/user-attachments/assets/e8638ca5-de24-4c0b-b7c0-876e4c1d1008" />

- ğŸ“º:[LeNet-5æ€»ç»“](https://www.bilibili.com/video/BV1e34y1M7wR?spm_id_from=333.788.videopod.episodes&vd_source=ee0d4853ce8dacb7fdfc07d40e328f36&p=34)

<img width="1319" height="659" alt="image" src="https://github.com/user-attachments/assets/ad648c98-c41e-4a5e-8abb-d5c0b56ef88b" />

### 2.LeNet-5æ¨¡å‹æ­å»º

**ä¾æ®å‰é¢è§†é¢‘è®²è§£çš„LeNet-5ç½‘ç»œå‚æ•°æ¥æ­å»ºç½‘ç»œ**

<img width="1296" height="633" alt="image" src="https://github.com/user-attachments/assets/e8638ca5-de24-4c0b-b7c0-876e4c1d1008" />

* ##### 2.1 å¯¼åŒ…

``` python
import torch
from torch import nn
from torchsummary import summary
```

* ##### 2.2 å®šä¹‰Lenetæ¨¡å—ç±»
![å¾®ä¿¡å›¾ç‰‡_20250902153651_46_28](https://github.com/user-attachments/assets/0efec7d0-22ac-49d6-aba9-f12d4f391e11)
![å¾®ä¿¡å›¾ç‰‡_20250902153656_47_28](https://github.com/user-attachments/assets/946bf3e5-c89e-4c48-a1ce-e3818f481352)

``` pyhon
#åˆå§‹åŒ–
class Lenet(nn.Module):
  def __init__(self):
    super().__init__()
#å®šä¹‰å±‚
    #ç¬¬ä¸€å·ç§¯å±‚ in_channels = 1 , out_channels = 6 , kernel_size = 5 , stride = 1 , padding = 2
    #in_channels = 1æ˜¯å› ä¸ºè¾“å…¥çš„å›¾åƒä¸ºå•é€šé“ï¼Œå³input:28*28*1ï¼Œå¦‚æœæ˜¯å½©è‰²å›¾ï¼Œå³28*28*3 åº”è¯¥æ”¹in_channelsä¸º3
    #out_channels = 6æ˜¯å› ä¸ºå·ç§¯æ ¸ä¸ªæ•°ä¸º6ï¼Œkernel_sizeå’Œstrideå’Œpaddingè®¾ç½®è¦ä¸æ”¹å˜å›¾åƒWå’ŒH


    **# å¦‚æœè®­ç»ƒ3x32x32çš„å›¾åƒï¼Œè¦æ”¹3ä¸ªåœ°æ–¹ï¼Œ
    # ç¬¬ä¸€å·ç§¯å±‚ in_channels = 1  => in_channels = 3
    # self.fc1 = nn.Linear(400, 120) => self.fc1 = nn.Linear(576, 120) è¿™é‡Œ576æ˜¯æ¯ä¸€å±‚è®¡ç®—å‡ºçš„ç»“æœ
    # print(summary(model,(1,28,28))) => print(summary(model,(3,32,32)))**

    self.conv1 = nn.Conv2d(1, 6, 5, 1, 2)
    self.sig = nn.Sigmoid()  # Sigmoidæ¿€æ´»å‡½æ•°
    self.pool = nn.AvgPool2d(2, 2)  # å¹³å‡æ± åŒ–
    self.conv2 = nn.Conv2d(6, 16, 5, 1, 0)  # stride=1å’Œpadding=0å¯ä»¥çœç•¥


    self.flatten = nn.Flatten()
    self.fc1 = nn.Linear(400, 120)
    self.fc2 = nn.Linear(120, 84)
    self.fc3 = nn.Linear(84, 10)
#å‰å‘ä¼ æ’­
    def forward(self, x):
        x = self.pool(self.sig(self.conv1(x)))
        x = self.pool(self.sig(self.conv2(x)))
        x = self.flatten(x)
        x = self.sig(self.fc1(x))
        x = self.sig(self.fc2(x))
        x = self.fc3(x)
        return x

* ##### 2.3 ä¸»å‡½æ•°
if __name__ == '__main__':
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = LeNet().to(device)
    print(summary(model,(1,28,28)))

```

* ##### 2.4 ä¸»å‡½æ•°è¿è¡Œç»“æœ

<img width="798" height="573" alt="image" src="https://github.com/user-attachments/assets/c372404d-b10c-4f5e-9ccc-5b38506237f1" />

### 3.LeNet-5æ¨¡å‹è®­ç»ƒ(å¯¼åŒ…+æ•°æ®åŠ è½½+è®­ç»ƒå’ŒéªŒè¯+å¯è§†åŒ–+ä¸»å‡½æ•°)

* ##### 3.1 å¯¼åŒ…

``` pyhon
import copy
import time
import pandas as pd
from torchvision.datasets import FashionMNIST
from torchvision import transforms
import torch.utils.data as data
from model import LeNet
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np
```

* ##### 3.2 æ•°æ®åŠ è½½

``` python
def train_val_process():

    transform = transforms.Compose([
        transforms.RandomCrop(28,2),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ToTensor(),
        transforms.Normalize((0.5,),(0.5,))
    ])


    full_data = FashionMNIST(root='./data',train=True,transform=transform,download=True)

    train_data,val_data = data.random_split(full_data,[round(0.8*len(full_data)),round(0.2*len(full_data))])

    train_dataloader = data.DataLoader(train_data,32,True,num_workers=0)
    val_dataloader = data.DataLoader(val_data,32,False,num_workers=0)

    return train_dataloader,val_dataloader
```

* ##### 3.3 è®­ç»ƒå’ŒéªŒè¯

``` python

def train_model(model,train_dataloader,val_dataloader,num_epoch):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    optimizer = torch.optim.AdamW(model.parameters(),lr=0.001)

    criterion = nn.CrossEntropyLoss()

    model = model.to(device)

    best_model_wts = copy.deepcopy(model.state_dict())

    best_acc = 0.0

    train_loss_all = []

    train_acc_all = []

    val_loss_all = []

    val_acc_all =[]

    since = time.time()

    for epoch in range(num_epoch):
        print(f'Epoch {epoch+1}/{num_epoch}')
        print('-'*30)

        epoch_time = time.time()
        train_loss = 0.0
        train_acc = 0.0
        train_num = 0
        val_loss = 0.0
        val_acc = 0.0
        val_num = 0

        model.train()
        t1 = time.time()
        for step,(inputs,targets) in enumerate(train_dataloader):
            inputs = inputs.to(device)
            targets = targets.to(device)



            outputs = model(inputs)

            pred = torch.argmax(outputs,dim=1)

            loss = criterion(outputs,targets)

            optimizer.zero_grad()

            loss.backward()

            optimizer.step()

            train_loss += loss.item()*inputs.size(0)

            train_acc += torch.sum(pred==targets).item()

            train_num += inputs.size(0)

        t2 = time.time()
        model.eval()
        with torch.no_grad():
            for step,(inputs,targets) in enumerate(val_dataloader):

                inputs = inputs.to(device)
                targets = targets.to(device)

                outputs = model(inputs)

                pred =torch.argmax(outputs,dim=1)

                loss = criterion(outputs,targets)

                val_loss += loss.item()*inputs.size(0)

                val_acc += torch.sum(pred==targets).item()

                val_num += inputs.size(0)
        t3 = time.time()

        train_loss_all.append(train_loss / train_num)
        train_acc_all.append(train_acc / train_num)
        val_loss_all.append(val_loss / val_num)
        val_acc_all.append(val_acc / val_num)

        print(f"Epoch:{epoch+1} Train_loss:{train_loss_all[-1]:.4f} Train_acc:{train_acc_all[-1]*100:.2f}")
        print(f"Epoch:{epoch+1} Val_loss:{val_loss_all[-1]:.4f} Val_acc:{val_acc_all[-1] * 100:.2f}")
        print(f"è®­ç»ƒæ—¶é—´:{t2 - t1:.2f} éªŒè¯æ—¶é—´:{t3 - t2:.2f} æ€»ç”¨æ—¶:{time.time()-epoch_time:.2f}")

        if val_acc_all[-1] > best_acc:
            best_acc = val_acc_all[-1]

            best_model_wts = copy.deepcopy(model.state_dict())

            torch.save(model.state_dict(),'./model.pth')

            print(f"éªŒè¯å‡†ç¡®ç‡ä¸º:{best_acc*100:.2f}")

    total = time.time() - since

    print(f"\n è®­ç»ƒå®Œæˆï¼Œæ€»ç”¨æ—¶ä¸º:{total//60:.0f}m{total%60:.0f}s")
    print(f"éªŒè¯å‡†ç¡®ç‡ä¸º:{best_acc*100:.2f}")

    model.load_state_dict(best_model_wts)

    train_process = pd.DataFrame(data={"epoch":range(1,num_epoch+1),
                                       "train_loss_all":train_loss_all,
                                       "train_acc_all":train_acc_all,
                                       "val_loss_all":val_loss_all,
                                       "val_acc_all":val_acc_all
                                       })
    return train_process

```

* ##### 3.4 å¯è§†åŒ–

``` python

def plot(train_process):
    plt.figure(figsize=(12,4))

    plt.subplot(121)

    plt.plot(train_process['epoch'],train_process['train_loss_all'],'-ro',label='train_loss')
    plt.plot(train_process['epoch'],train_process['val_loss_all'],'-ro',label='val_loss')
    plt.legend()
    plt.xlabel('epoch')
    plt.ylabel('loss')

    plt.subplot(122)
    plt.plot(train_process['epoch'],train_process['train_acc_all'],'-ro',label='train_acc')
    plt.plot(train_process['epoch'],train_process['val_acc_all'],'-ro',label='val_acc')
    plt.legend()
    plt.xlabel('epoch')
    plt.ylabel('acc')

    plt.show()

```

* ##### 3.5 ä¸»å‡½æ•°

``` python
if __name__ == '__main__':
    model = LeNet()

    train_dataloader,val_dataloader = train_val_process()

    train_process = train_model(model,train_dataloader,val_dataloader,100)

    plot(train_process)

```
